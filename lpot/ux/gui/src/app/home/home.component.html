<br>
<p class="intro">
  <br>
  <br>
  Intel® Low Precision Optimization Tool (LPOT) supports automatic quantization tuning flow by converting
  quantizable layers to INT8 and allowing users to control model accuracy and performance tradeoffs
  and implements the latest quantization algorithms from the research community.
  <br>
  <br>
  Visit the Intel® LPOT online document website at:
  <a href="https://intel.github.io/lpot">https://intel.github.io/lpot</a>.
</p>

<div class="cards">
  <mat-card [routerLink]="'/model-zoo'" queryParamsHandling="preserve" class="inline-block pointer">
    <br>
    <div class="img-container">
      <img class="big-icon" src="./../../assets/nn.png">
    </div>
    <h1 class="center margin-top">Quantize from presets</h1>
    <h3>Choose model from predefined quantization configurations.</h3>
  </mat-card>
  or
  <mat-card [routerLink]="'/config-wizard'" queryParamsHandling="preserve" class="inline-block pointer">
    <br>
    <div class="img-container">
      <img class="big-icon" src="./../../assets/create-new.png">
    </div>
    <h1 class="center margin-top">Quantize new configuration</h1>
    <h3>Create a new quantization configuration.</h3>
  </mat-card>
</div>